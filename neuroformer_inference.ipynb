{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/antonis/.conda/envs/neuroformer_clean/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter\n",
      "CONTRASTIUVEEEEEEE False\n",
      "VISUAL: True\n",
      "PAST_STATE: True\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\xef'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 63\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVISUAL: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m.\u001b[39mvisual\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPAST_STATE: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m.\u001b[39mpast_state\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m config, tokenizer, model \u001b[39m=\u001b[39m load_model_and_tokenizer(args\u001b[39m.\u001b[39;49mckpt_path)\n",
      "File \u001b[0;32m/share/edc/home/antonis/neuroformer_clean/Neuroformer/neuroformer/model_neuroformer.py:44\u001b[0m, in \u001b[0;36mload_model_and_tokenizer\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model_and_tokenizer\u001b[39m(path):\n\u001b[1;32m     43\u001b[0m     config \u001b[39m=\u001b[39m load_config(path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/mconf.yaml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     tokenizer \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/tokenizer.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     45\u001b[0m     model \u001b[39m=\u001b[39m Neuroformer(config, tokenizer)\n\u001b[1;32m     46\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m ///// <=----- Loading model from \u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m -----=> \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\xef'."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from neuroformer.model_neuroformer import load_model_and_tokenizer\n",
    "from neuroformer.utils import get_attr\n",
    "from neuroformer.utils import (set_seed, running_jupyter, \n",
    "                                 all_device, recursive_print,\n",
    "                                 create_modalities_dict)\n",
    "from neuroformer.datasets import load_visnav, load_V1AL\n",
    "\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "\n",
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "\n",
    "from neuroformer.default_args import DefaultArgs, parse_args\n",
    "\n",
    "if running_jupyter(): # or __name__ == \"__main__\":\n",
    "    print(\"Running in Jupyter\")\n",
    "    args = DefaultArgs()\n",
    "    # args.dataset = \"medial\"\n",
    "    # args.ckpt_path = \"./models/NF.15/Visnav_VR_Expt/medial/Neuroformer/predict_all_behavior/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25\"\n",
    "    \n",
    "    args.dataset = \"lateral\"\n",
    "    args.ckpt_path = \"./models/predict_all_behavior/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25\"\n",
    "    args.predict_modes = ['speed', 'phi', 'th']\n",
    "else:\n",
    "    print(\"Running in terminal\")\n",
    "    args = parse_args()\n",
    "\n",
    "\n",
    "# SET SEED - VERY IMPORTANT\n",
    "set_seed(args.seed)\n",
    "\n",
    "print(f\"CONTRASTIUVEEEEEEE {args.contrastive}\")\n",
    "print(f\"VISUAL: {args.visual}\")\n",
    "print(f\"PAST_STATE: {args.past_state}\")\n",
    "\n",
    "\n",
    "config, tokenizer, model = load_model_and_tokenizer(args.ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "-- DATA --\n",
    "neuroformer/data/OneCombo3_V1AL/\n",
    "df = response\n",
    "video_stack = stimulus\n",
    "DOWNLOAD DATA URL = https://drive.google.com/drive/folders/1jNvA4f-epdpRmeG9s2E-2Sfo-pwYbjeY?usp=sharing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(f\"DATASET: {args.dataset}\")\n",
    "if args.dataset in [\"lateral\", \"medial\"]:\n",
    "    data, intervals, train_intervals, \\\n",
    "    test_intervals, finetune_intervals, \\\n",
    "    callback = load_visnav(args.dataset, config, \n",
    "                           selection=config.selection if hasattr(config, \"selection\") else None)\n",
    "elif args.dataset == \"V1AL\":\n",
    "    data, intervals, train_intervals, \\\n",
    "    test_intervals, finetune_intervals, \\\n",
    "    callback = load_V1AL(config)\n",
    "\n",
    "spikes = data['spikes']\n",
    "stimulus = data['stimulus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = config.window.curr\n",
    "window_prev = config.window.prev\n",
    "dt = config.resolution.dt\n",
    "\n",
    "\n",
    "# -------- #\n",
    "\n",
    "spikes_dict = {\n",
    "    \"ID\": data['spikes'],\n",
    "    \"Frames\": data['stimulus'],\n",
    "    \"Interval\": intervals,\n",
    "    \"dt\": config.resolution.dt,\n",
    "    \"id_block_size\": config.block_size.id,\n",
    "    \"prev_id_block_size\": config.block_size.prev_id,\n",
    "    \"frame_block_size\": config.block_size.frame,\n",
    "    \"window\": config.window.curr,\n",
    "    \"window_prev\": config.window.prev,\n",
    "    \"frame_window\": config.window.frame,\n",
    "}\n",
    "\n",
    "\"\"\" structure:\n",
    "{\n",
    "    type_of_modality:\n",
    "        {name of modality: {'data':data, 'dt': dt, 'predict': True/False},\n",
    "        ...\n",
    "        }\n",
    "    ...\n",
    "}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.data_utils import NFDataloader\n",
    "\n",
    "modalities = create_modalities_dict(data, config.modalities)\n",
    "frames = {'feats': stimulus, 'callback': callback, 'window': config.window.frame, 'dt': config.resolution.dt}\n",
    "\n",
    "train_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                             frames=frames, intervals=train_intervals, modalities=modalities)\n",
    "test_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                            frames=frames, intervals=test_intervals, modalities=modalities)\n",
    "finetune_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                                frames=frames, intervals=finetune_intervals, modalities=modalities)\n",
    "\n",
    "    \n",
    "# print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')\n",
    "iterable = iter(train_dataset)\n",
    "x, y = next(iterable)\n",
    "recursive_print(x)\n",
    "\n",
    "# Update the config\n",
    "config.id_vocab_size = tokenizer.ID_vocab_size\n",
    "\n",
    "# Create a DataLoader\n",
    "loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "iterable = iter(loader)\n",
    "x, y = next(iterable)\n",
    "recursive_print(y)\n",
    "preds, features, loss = model(x, y)\n",
    "\n",
    "# Set training parameters\n",
    "MAX_EPOCHS = 300\n",
    "BATCH_SIZE = 32 * 5\n",
    "SHUFFLE = True\n",
    "\n",
    "if config.gru_only:\n",
    "    model_name = \"GRU\"\n",
    "elif config.mlp_only:\n",
    "    model_name = \"MLP\"\n",
    "elif config.gru2_only:\n",
    "    model_name = \"GRU_2.0\"\n",
    "else:\n",
    "    model_name = \"Neuroformer\"\n",
    "\n",
    "# CKPT_PATH = f\"/share/edc/home/antonis/neuroformer/models/NF.15/Visnav_VR_Expt/{DATASET}/{model_name}/1_new/{str(config.layers)}/{str(config.window)}/{SEED}\"\n",
    "# CKPT_PATH = CKPT_PATH.replace(\"namespace\", \"\").replace(\" \", \"_\")\n",
    "CKPT_PATH = args.ckpt_path\n",
    "\n",
    "# Define the parameters\n",
    "sample = True\n",
    "top_p = 0.95\n",
    "top_p_t = 0.95\n",
    "temp = 1.\n",
    "temp_t = 1.\n",
    "frame_end = 0\n",
    "true_past = args.true_past\n",
    "get_dt = True\n",
    "gpu = True\n",
    "pred_dt = True\n",
    "\n",
    "# # Run the prediction function\n",
    "# results_trial = generate_spikes(model, test_dataset, window, \n",
    "#                                 window_prev, tokenizer, \n",
    "#                                 sample=sample, top_p=top_p, top_p_t=top_p_t, \n",
    "#                                 temp=temp, temp_t=temp_t, frame_end=frame_end, \n",
    "#                                 true_past=true_past,\n",
    "#                                 get_dt=get_dt, gpu=gpu, pred_dt=pred_dt,\n",
    "#                                 plot_probs=False)\n",
    "\n",
    "# # Create a filename string with the parameters\n",
    "# filename = f\"results_trial_sample-{sample}_top_p-{top_p}_top_p_t-{top_p_t}_temp-{temp}_temp_t-{temp_t}_frame_end-{frame_end}_true_past-{true_past}_get_dt-{get_dt}_gpu-{gpu}_pred_dt-{pred_dt}.pkl\"\n",
    "\n",
    "# # Save the results in a pickle file\n",
    "# save_inference_path = os.path.join(CKPT_PATH, \"inference\")\n",
    "# if not os.path.exists(save_inference_path):\n",
    "#     os.makedirs(save_inference_path)\n",
    "\n",
    "# print(f\"Saving inference results in {os.path.join(save_inference_path, filename)}\")\n",
    "\n",
    "# with open(os.path.join(save_inference_path, filename), \"wb\") as f:\n",
    "#     pickle.dump(results_trial, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict other modality\n",
    "from neuroformer.utils import decode_modality\n",
    "# model.load_state_dict(torch.load(os.path.join(CKPT_PATH, f\"_epoch_speed.pt\"), map_location=torch.device('cpu')))\n",
    "model.load_state_dict(torch.load(os.path.join(CKPT_PATH, f\"model.pt\"), map_location=torch.device('cpu')))\n",
    "args.predict_modes = ['speed', 'phi', 'th']\n",
    "behavior_preds = {}\n",
    "if args.predict_modes is not None:\n",
    "    block_type = 'behavior'\n",
    "    block_config = get_attr(config.modalities, block_type).variables\n",
    "    for mode in args.predict_modes:\n",
    "        mode_config = get_attr(block_config, mode)\n",
    "        behavior_preds[mode] = decode_modality(model, test_dataset, modality=mode, \n",
    "                                          block_type=block_type, objective=get_attr(mode_config, 'objective'))\n",
    "        filename = f\"behavior_preds_{mode}.csv\"\n",
    "        save_inference_path = os.path.join(CKPT_PATH, \"inference\")\n",
    "        if not os.path.exists(save_inference_path):\n",
    "            os.makedirs(save_inference_path)\n",
    "        print(f\"Saving inference results in {os.path.join(save_inference_path, filename)}\")\n",
    "        behavior_preds.to_csv(os.path.join(save_inference_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression(y_true, y_pred, mode, model_name, r, p, color='black', \n",
    "                    ax=None, axis_limits=None, save_path=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    \n",
    "    ax.scatter(y_true, y_pred, s=100, alpha=0.5, color=color)\n",
    "\n",
    "    xlims = ax.get_xlim()\n",
    "    ylims = ax.get_ylim()\n",
    "    s_f = 0.8\n",
    "    combined_limits = [min(xlims[0], ylims[0]) * s_f, max(xlims[1], ylims[1]) * s_f]\n",
    "    ax.plot(combined_limits, combined_limits, 'k--', color='black')\n",
    "\n",
    "    ax.set_xlabel(f'True {mode}', fontsize=20)\n",
    "    ax.set_ylabel(f'Predicted {mode}', fontsize=20)\n",
    "    # ax.set_title(f'{model_name}, Regression', fontsize=20)\n",
    "    ax.text(0.05, 0.9, 'r = {:.2f}'.format(r), fontsize=20, transform=ax.transAxes)\n",
    "    ax.text(0.05, 0.8, 'p < 0.001'.format(p), fontsize=20, transform=ax.transAxes)\n",
    "\n",
    "    if axis_limits is not None:\n",
    "        ax.set_xlim(axis_limits)\n",
    "        ax.set_ylim(axis_limits)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, 'regression_2.pdf'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17.5, 5), nrows=1, ncols=len(args.predict_modes))\n",
    "plt.suptitle(f'Visnav {args.dataset} Multitask Decoding - Speed + Eye Gaze (phi, th)', fontsize=20, y=1.01)\n",
    "colors = ['limegreen', 'royalblue', 'darkblue']  # Define your colors here\n",
    "\n",
    "for n, mode in enumerate(args.predict_modes):\n",
    "    behavior_preds_mode = behavior_preds[mode]\n",
    "    x_true, y_true = behavior_preds_mode['cum_interval'][:200], behavior_preds_mode['true'][:200]  # Limit to 200 examples\n",
    "    x_pred, y_pred = behavior_preds_mode['cum_interval'][:200], behavior_preds_mode[f'behavior_{mode}_value'][:200]  # Limit to 200 examples\n",
    "    r, p = pearsonr([float(y) for y in y_pred], [float(y) for y in y_true])\n",
    "    axis = ax[n]\n",
    "    plot_regression(y_true, y_pred, mode, model_name, r, p, ax=axis, color=colors[n], save_path=args.ckpt_path)  # Use color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
